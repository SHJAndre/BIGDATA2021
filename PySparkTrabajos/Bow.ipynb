{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Bow(Haskell): Traducido PySpark**\n",
    "```\n",
    "NOMBRE: JORGE ANDRE SALCEDO HURTADO\n",
    "CURSO: MINERIA DE DATOS\n",
    "DOCENTE: CARLOS FERNANDO MONTOYA CUBAS\n",
    "```\n",
    "\n",
    "#### Implementar los algoritmos del archivo bow.hs en PySpark\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Inicializamos nuestra variable de pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/01/09 12:53:54 WARN Utils: Your hostname, MR resolves to a loopback address: 127.0.1.1; using 192.168.1.20 instead (on interface enp9s0)\n",
      "22/01/09 12:53:54 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/home/andre/spark-3.2.0-bin-hadoop3.2/jars/spark-unsafe_2.12-3.2.0.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/01/09 12:53:55 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "22/01/09 12:53:55 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "from pyspark import SparkContext\n",
    "sc =SparkContext()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Implementación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Bag of Words\n",
    "El modelo \"bolsa de palabras\" es un método que se utiliza en el procesado del lenguaje para representar documentos ignorando el orden de las palabras. En este modelo, cada documento parece una bolsa que contiene algunas palabras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bagOfWords(corpus = []):\n",
    "    \"\"\"Devuelve el corpus con todas las letras cambiadas a minuscula, quita espacios en blanco y las letras mayores a 2\n",
    "\n",
    "    Args:\n",
    "        corpus (List): Lista de textos(corpus).\n",
    "\n",
    "    Returns:\n",
    "        str: El corpus procesado.\n",
    "    \"\"\"\n",
    "    # creamos la RDD en base al corpus\n",
    "    bow = sc.parallelize(corpus)\n",
    "    # eliminamos las lineas en blanco\n",
    "    bow = bow.filter(lambda x: len(x)>0)\n",
    "    # separamos en palabras cada linea\n",
    "    bow = bow.map(lambda x: x.split(\" \"))\n",
    "    \n",
    "    # realizamos una iteracion por cada palabra dentro de cada linea\n",
    "    # la funcion lambda interna devuelve las palabras en minuscula\n",
    "    bow = bow.map(lambda text: list(map((lambda word: word.lower()),text)))\n",
    "    \n",
    "    # eliminamos las palabras que tengan una longitud menor a 2\n",
    "    bow = bow.map(lambda text: list(filter(lambda word: len(word)>2,text)))\n",
    "    return bow.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['project', 'gutenberg’s', 'the', 'complete', 'works', 'william', 'shakespeare,', 'william'], ['shakespeare'], ['this', 'ebook', 'for', 'the', 'use', 'anyone', 'anywhere', 'the', 'united', 'states', 'and'], ['most', 'other', 'parts', 'the', 'world', 'cost', 'and', 'with', 'almost', 'restrictions'], ['whatsoever.', 'you', 'may', 'copy', 'it,', 'give', 'away', 're-use', 'under', 'the', 'terms'], ['the', 'project', 'gutenberg', 'license', 'included', 'with', 'this', 'ebook', 'online'], ['www.gutenberg.org.', 'you', 'are', 'not', 'located', 'the', 'united', 'states,', 'you’ll'], ['have', 'check', 'the', 'laws', 'the', 'country', 'where', 'you', 'are', 'located', 'before', 'using'], ['this', 'ebook.']]\n"
     ]
    }
   ],
   "source": [
    "Corpus = [\"Project Gutenberg’s The Complete Works of William Shakespeare, by William\",\n",
    "            \"Shakespeare\",\n",
    "            \"This eBook is for the use of anyone anywhere in the United States and\",\n",
    "            \"most other parts of the world at no cost and with almost no restrictions\",\n",
    "            \"whatsoever.  You may copy it, give it away or re-use it under the terms\",\n",
    "            \"of the Project Gutenberg License included with this eBook or online at\",\n",
    "            \"www.gutenberg.org.  If you are not located in the United States, you’ll\",\n",
    "            \"have to check the laws of the country where you are located before using\",\n",
    "            \"this ebook.\"]\n",
    "print(bagOfWords(Corpus))         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. ***TF*** (Term Frecuency): Es la frecuencia con la que aparece la palabra en un documento del corpus. Esta se define como:\n",
    "    \n",
    "### $$tf(t,d) = 1 + log(f_{t,d})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def tf(corpus = []):\n",
    "    \"\"\"Halla el TF(Term Frecuency) de un conjunto de documentos.\n",
    "\n",
    "    Args:\n",
    "        corpus (List): Lista de textos(corpus).\n",
    "\n",
    "    Returns:\n",
    "        str: Una lista de tuplas compuesto por (palabra, TF).\n",
    "    \"\"\"\n",
    "    # creamos la RDD en base al corpus\n",
    "    tfRDD = sc.parallelize(corpus)\n",
    "    # separamos en palabras cada tweet\n",
    "    tfRDD = tfRDD.map(lambda x: x.split(\" \"))\n",
    "    # realizamos una iteracion por cada palabra dentro de cada tweet\n",
    "    # la funcion lambda interna devuelve en una tupla:\n",
    "    # 1. La palabra\n",
    "    # 2. La operacion de TF, para lo cual se halla el conteo de la palabra en el tweet que se \n",
    "    # esté analizando ese momento y la longitud del tweet\n",
    "    tfRDD = tfRDD.map(lambda tweet: tuple(map((lambda word: (word, 1+np.log10(tweet.count(word)/len(tweet)))),tweet))).collect()\n",
    "    # finalmente debido a que puede haber palabras repetidas para las que se hallo el TF, \n",
    "    # con una operacion set, eliminamos estos repetidos\n",
    "    tfLista = list(map(set,tfRDD))\n",
    "    # devolvemos una lista, donde cada elemento es otra lista de tuplas que contiene la palabra y su TF\n",
    "    return tfLista"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejecucion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{('of', 0.0), ('Project', 0.0), ('The', 0.0), ('Shakespeare,', 0.0), ('Gutenberg’s', 0.0), ('Complete', 0.0), ('Works', 0.0), ('by', 0.0), ('William', 0.30102999566398125)}\n",
      "{('Shakespeare', 1.0)}\n",
      "{('This', -0.14612803567823818), ('eBook', -0.14612803567823818), ('is', -0.14612803567823818), ('States', -0.14612803567823818), ('anywhere', -0.14612803567823818), ('and', -0.14612803567823818), ('United', -0.14612803567823818), ('the', 0.15490195998574308), ('use', -0.14612803567823818), ('for', -0.14612803567823818), ('of', -0.14612803567823818), ('in', -0.14612803567823818), ('anyone', -0.14612803567823818)}\n",
      "{('parts', -0.14612803567823818), ('the', -0.14612803567823818), ('and', -0.14612803567823818), ('restrictions', -0.14612803567823818), ('other', -0.14612803567823818), ('cost', -0.14612803567823818), ('of', -0.14612803567823818), ('at', -0.14612803567823818), ('world', -0.14612803567823818), ('no', 0.15490195998574308), ('almost', -0.14612803567823818), ('most', -0.14612803567823818), ('with', -0.14612803567823818)}\n",
      "{('give', -0.17609125905568135), ('', -0.17609125905568135), ('whatsoever.', -0.17609125905568135), ('You', -0.17609125905568135), ('away', -0.17609125905568135), ('it,', -0.17609125905568135), ('copy', -0.17609125905568135), ('or', -0.17609125905568135), ('re-use', -0.17609125905568135), ('terms', -0.17609125905568135), ('the', -0.17609125905568135), ('it', 0.1249387366082999), ('under', -0.17609125905568135), ('may', -0.17609125905568135)}\n",
      "{('Project', -0.07918124604762489), ('with', -0.07918124604762489), ('this', -0.07918124604762489), ('or', -0.07918124604762489), ('the', -0.07918124604762489), ('of', -0.07918124604762489), ('Gutenberg', -0.07918124604762489), ('included', -0.07918124604762489), ('at', -0.07918124604762489), ('online', -0.07918124604762489), ('eBook', -0.07918124604762489), ('License', -0.07918124604762489)}\n",
      "{('If', -0.07918124604762489), ('are', -0.07918124604762489), ('located', -0.07918124604762489), ('you', -0.07918124604762489), ('www.gutenberg.org.', -0.07918124604762489), ('States,', -0.07918124604762489), ('you’ll', -0.07918124604762489), ('the', -0.07918124604762489), ('United', -0.07918124604762489), ('in', -0.07918124604762489), ('not', -0.07918124604762489), ('', -0.07918124604762489)}\n",
      "{('are', -0.14612803567823818), ('check', -0.14612803567823818), ('located', -0.14612803567823818), ('using', -0.14612803567823818), ('to', -0.14612803567823818), ('you', -0.14612803567823818), ('have', -0.14612803567823818), ('the', 0.15490195998574308), ('of', -0.14612803567823818), ('laws', -0.14612803567823818), ('country', -0.14612803567823818), ('where', -0.14612803567823818), ('before', -0.14612803567823818)}\n",
      "{('this', 0.6989700043360187), ('ebook.', 0.6989700043360187)}\n"
     ]
    }
   ],
   "source": [
    "tfValues = tf(Corpus)\n",
    "# mostramos el resultado\n",
    "for line in tfValues:\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 ***IDF*** (Inverse Document Frequency): La frecuencia inversa del documento nos indica lo común que es una palabra en el corpus.\n",
    "    \n",
    "###    $$idf(t,D) = log(1 + \\frac{N}{n_t})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def idf(corpus = []):\n",
    "    \"\"\"Halla el IDF(Inverse Document Frequency) de un conjunto de documentos.\n",
    "\n",
    "    Args:\n",
    "        corpus (List): Lista de los textos(corpus).\n",
    "\n",
    "    Returns:\n",
    "        str: Una lista de tuplas compuesto por (palabra, IDF).\n",
    "    \"\"\" \n",
    "    # obtenemos el numero total de tweets(documentos)\n",
    "    total = len(corpus)\n",
    "    # creamos la RDD a partir del corpus\n",
    "    idfRDD = sc.parallelize(corpus)\n",
    "    # realizamos para cada tweet la supresion de terminos repetidos, y al usar la funcion flatMap\n",
    "    # nos devuelve todos las palabras unicas por tweet en un solo conjunto.\n",
    "    idfRDD = idfRDD.flatMap(lambda x: list(set(x.split(\" \"))))\n",
    "    # asignamos el numero 1 a cada palabra y posteriormente sumamos segun su key.\n",
    "    idfRDD = idfRDD.map(lambda x: (x,1)).reduceByKey(lambda x,y: x+y)\n",
    "    # aplicamos la formula de idf, utilizando el numero total de documentos\n",
    "    #  y el término anteriormente hallado para cada palabra\n",
    "    idfRDD = idfRDD.map(lambda x: (x[0], np.log10(1 + total/x[1])))\n",
    "    # finalmente devolvemos una lista de tuplas conformado por, la palabra y su termino idf\n",
    "    return list(idfRDD.collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejecucion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('other', 1.0), ('', 0.7403626894942439), ('where', 1.0), ('William', 1.0), ('by', 1.0), ('cost', 1.0), ('almost', 1.0), ('you', 0.7403626894942439), ('use', 1.0), ('States', 1.0), ('at', 0.7403626894942439), ('this', 0.7403626894942439), ('online', 1.0), ('copy', 1.0), ('located', 0.7403626894942439), ('If', 1.0), ('in', 0.7403626894942439), ('it,', 1.0), ('the', 0.3979400086720376), ('most', 1.0), ('You', 1.0), ('ebook.', 1.0), ('Project', 0.7403626894942439), ('anywhere', 1.0), ('United', 0.7403626894942439), ('restrictions', 1.0), ('before', 1.0), ('Gutenberg', 1.0), ('States,', 1.0), ('laws', 1.0), ('of', 0.4471580313422192), ('Gutenberg’s', 1.0), ('are', 0.7403626894942439), ('using', 1.0), ('check', 1.0), ('Works', 1.0), ('terms', 1.0), ('you’ll', 1.0), ('anyone', 1.0), ('for', 1.0), ('This', 1.0), ('under', 1.0), ('it', 1.0), ('included', 1.0), ('Shakespeare', 1.0), ('no', 1.0), ('give', 1.0), ('away', 1.0), ('re-use', 1.0), ('may', 1.0), ('whatsoever.', 1.0), ('country', 1.0), ('have', 1.0), ('Shakespeare,', 1.0), ('eBook', 0.7403626894942439), ('and', 0.7403626894942439), ('www.gutenberg.org.', 1.0), ('to', 1.0), ('The', 1.0), ('is', 1.0), ('world', 1.0), ('Complete', 1.0), ('with', 0.7403626894942439), ('parts', 1.0), ('or', 0.7403626894942439), ('License', 1.0), ('not', 1.0)]\n"
     ]
    }
   ],
   "source": [
    "idfValues = idf(Corpus)\n",
    "# mostramos el resultado\n",
    "print(idfValues)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Term Frequency-Inverse Document Frequency (TF-IDF)\n",
    "\n",
    "\n",
    "* El TF-IDF (Frecuencia de Termino - Frecuencia Inversa de Documento) es una medida numérica que permite expresar como de relevante es una palabra para un documento en una colección de documentos (o corpus).\n",
    "\n",
    "\n",
    "* Construir la Bolsa de Palabras con TF-IDF en vez de con frecuencias evita dar \"importancia\" a texto muy largos y con mucha repetición de palabras, frente a textos cortos y con pocas repeticiones de palabras.\n",
    "\n",
    "* ***TF-IDF*** queda definido como:\n",
    "### $$tfidf(t,d,D) = tf(t,d) \\cdot idf(t,D)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_idf(corpus = []):\n",
    "    \"\"\"Halla el TF-IDF de un conjunto de documentos.\n",
    "\n",
    "    Args:\n",
    "        corpus (List): Lista de los textos(corpus).\n",
    "\n",
    "    Returns:\n",
    "        str: Una lista de tuplas compuesto por (palabra, TF-IDF).\n",
    "    \"\"\" \n",
    "    # generamos la lista de terminos y sus TF de nuestro corpus\n",
    "    tfList = tf(corpus)\n",
    "    # generamos la lista de terminos y sus IDF de nuestro corpus\n",
    "    idfList = idf(corpus)\n",
    "    # declaramos un diccionario vacio\n",
    "    idfDict = {}\n",
    "    # convertimos nuestra lista de tuplas de terminos IDF para poder llamarlos de mejro manera\n",
    "    idfDict = dict(idfList)\n",
    "    \n",
    "    # creamos una RDD a partir de nuestro conjunto de palabras y sus TF\n",
    "    tfIdfRDD = sc.parallelize(tfList)\n",
    "    # recorremos cada palabra por cada Tweet para multiplicar su TF por el IDF correspondiente \n",
    "    # y hallar el TFIDF\n",
    "    tfIdfRDD = tfIdfRDD.map(lambda twiit: tuple(map(lambda word: (word[0],word[1]*idfDict[word[0]]),twiit)))\n",
    "    # devolvemos la lista de palabras con su respectivo TF-IDF\n",
    "    return list(tfIdfRDD.collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ejecucion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('by', 0.0), ('Project', 0.0), ('of', 0.0), ('Works', 0.0), ('Shakespeare,', 0.0), ('Complete', 0.0), ('Gutenberg’s', 0.0), ('The', 0.0), ('William', 0.30102999566398125))\n",
      "(('Shakespeare', 1.0),)\n",
      "(('States', -0.14612803567823818), ('use', -0.14612803567823818), ('the', 0.06164168730004222), ('of', -0.06534232475778655), ('for', -0.14612803567823818), ('is', -0.14612803567823818), ('in', -0.10818774550525125), ('United', -0.10818774550525125), ('eBook', -0.10818774550525125), ('This', -0.14612803567823818), ('and', -0.10818774550525125), ('anywhere', -0.14612803567823818), ('anyone', -0.14612803567823818))\n",
      "(('the', -0.05815019178502592), ('most', -0.14612803567823818), ('of', -0.06534232475778655), ('no', 0.15490195998574308), ('world', -0.14612803567823818), ('restrictions', -0.14612803567823818), ('parts', -0.14612803567823818), ('other', -0.14612803567823818), ('cost', -0.14612803567823818), ('almost', -0.14612803567823818), ('and', -0.10818774550525125), ('with', -0.10818774550525125), ('at', -0.10818774550525125))\n",
      "(('', -0.13037139815089188), ('the', -0.07007375715568785), ('it,', -0.17609125905568135), ('or', -0.13037139815089188), ('terms', -0.17609125905568135), ('give', -0.17609125905568135), ('it', 0.1249387366082999), ('may', -0.17609125905568135), ('You', -0.17609125905568135), ('whatsoever.', -0.17609125905568135), ('copy', -0.17609125905568135), ('re-use', -0.17609125905568135), ('under', -0.17609125905568135), ('away', -0.17609125905568135))\n",
      "(('the', -0.03150938573885459), ('or', -0.05862284028132503), ('Gutenberg', -0.07918124604762489), ('of', -0.03540653010187982), ('online', -0.07918124604762489), ('this', -0.05862284028132503), ('License', -0.07918124604762489), ('included', -0.07918124604762489), ('eBook', -0.05862284028132503), ('at', -0.05862284028132503), ('Project', -0.05862284028132503), ('with', -0.05862284028132503))\n",
      "(('the', -0.03150938573885459), ('www.gutenberg.org.', -0.07918124604762489), ('are', -0.05862284028132503), ('located', -0.05862284028132503), ('you', -0.05862284028132503), ('States,', -0.07918124604762489), ('not', -0.07918124604762489), ('If', -0.07918124604762489), ('you’ll', -0.07918124604762489), ('in', -0.05862284028132503), ('United', -0.05862284028132503), ('', -0.05862284028132503))\n",
      "(('located', -0.10818774550525125), ('check', -0.14612803567823818), ('country', -0.14612803567823818), ('you', -0.10818774550525125), ('the', 0.06164168730004222), ('before', -0.14612803567823818), ('where', -0.14612803567823818), ('laws', -0.14612803567823818), ('using', -0.14612803567823818), ('of', -0.06534232475778655), ('to', -0.14612803567823818), ('have', -0.14612803567823818), ('are', -0.10818774550525125))\n",
      "(('this', 0.5174913122860182), ('ebook.', 0.6989700043360187))\n"
     ]
    }
   ],
   "source": [
    "tfIDFValues = tf_idf(Corpus)\n",
    "# mostramos el resultado\n",
    "for tweet in tfIDFValues:\n",
    "    print(tweet)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
